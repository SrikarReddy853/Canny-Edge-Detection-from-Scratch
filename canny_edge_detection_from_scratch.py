# -*- coding: utf-8 -*-
"""Canny Edge Detection from Scratch

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gQDHCvLw2XHvziFdLYDPBe-rM7XpKRxE
"""

# LAB–4: Canny Edge Detection from Scratch (Stable, No Flicker)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
import os

# ---------- DISPLAY FIXES (IMPORTANT) ----------
plt.rcParams['figure.autolayout'] = True
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

# =========================================================
# 1. UPLOAD ONE IMAGE
# =========================================================
os.makedirs('/mnt/data/', exist_ok=True)

print("Upload ONE image:")
uploaded = files.upload()

filename = list(uploaded.keys())[0]
filepath = f"/mnt/data/{filename}"

with open(filepath, "wb") as f:
    f.write(uploaded[filename])

# Read image and convert to grayscale
img = cv2.imread(filepath)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# =========================================================
# 2. STAGE 1: GAUSSIAN BLUR
# =========================================================
gaussian = cv2.GaussianBlur(gray, (5, 5), 1.4)

# =========================================================
# 3. STAGE 2: SOBEL GRADIENTS
# =========================================================
sobel_x = cv2.Sobel(gaussian, cv2.CV_64F, 1, 0, ksize=3)
sobel_y = cv2.Sobel(gaussian, cv2.CV_64F, 0, 1, ksize=3)

gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
gradient_magnitude = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)

gradient_direction = np.arctan2(sobel_y, sobel_x)

# =========================================================
# 4. STAGE 3: NON-MAXIMUM SUPPRESSION
# =========================================================
def non_max_suppression(mag, ang):
    H, W = mag.shape
    out = np.zeros((H, W), dtype=np.uint8)
    ang = ang * 180.0 / np.pi
    ang[ang < 0] += 180

    for i in range(1, H-1):
        for j in range(1, W-1):
            q = r = 0

            if (0 <= ang[i,j] < 22.5) or (157.5 <= ang[i,j] <= 180):
                q, r = mag[i, j+1], mag[i, j-1]
            elif (22.5 <= ang[i,j] < 67.5):
                q, r = mag[i-1, j+1], mag[i+1, j-1]
            elif (67.5 <= ang[i,j] < 112.5):
                q, r = mag[i-1, j], mag[i+1, j]
            elif (112.5 <= ang[i,j] < 157.5):
                q, r = mag[i-1, j-1], mag[i+1, j+1]

            if mag[i,j] >= q and mag[i,j] >= r:
                out[i,j] = mag[i,j]

    return out

nms = non_max_suppression(gradient_magnitude, gradient_direction)

# =========================================================
# 5. STAGE 4: HYSTERESIS THRESHOLDING
# =========================================================
def hysteresis(img, low, high):
    H, W = img.shape
    res = np.zeros((H, W), dtype=np.uint8)

    strong, weak = 255, 75
    strong_i, strong_j = np.where(img >= high)
    weak_i, weak_j = np.where((img >= low) & (img < high))

    res[strong_i, strong_j] = strong
    res[weak_i, weak_j] = weak

    for i in range(1, H-1):
        for j in range(1, W-1):
            if res[i,j] == weak:
                if np.any(res[i-1:i+2, j-1:j+2] == strong):
                    res[i,j] = strong
                else:
                    res[i,j] = 0
    return res

final_edges = hysteresis(nms, low=30, high=80)

# =========================================================
# 6. DISPLAY RESULTS (STABLE)
# =========================================================
plt.figure(figsize=(15, 10))

plt.subplot(2,3,1)
plt.imshow(gray, vmin=0, vmax=255)
plt.title("Original Grayscale")
plt.axis("off")

plt.subplot(2,3,2)
plt.imshow(gaussian, vmin=0, vmax=255)
plt.title("Stage 1: Gaussian Blur")
plt.axis("off")

plt.subplot(2,3,3)
plt.imshow(gradient_magnitude, vmin=0, vmax=255)
plt.title("Stage 2a: Gradient Magnitude")
plt.axis("off")

plt.subplot(2,3,4)
plt.imshow(np.abs(gradient_direction), vmin=0, vmax=np.pi)
plt.title("Stage 2b: Gradient Direction")
plt.axis("off")

plt.subplot(2,3,5)
plt.imshow(nms, vmin=0, vmax=255)
plt.title("Stage 3: Non-Max Suppression")
plt.axis("off")

plt.subplot(2,3,6)
plt.imshow(final_edges, vmin=0, vmax=255)
plt.title("Stage 4: Final Edges (Hysteresis)")
plt.axis("off")

plt.show()

# Lab-2: Image Transformations (OpenCV + NumPy)


!pip install --quiet opencv-python-headless matplotlib

import os, cv2, numpy as np
import matplotlib.pyplot as plt
from math import cos, sin, radians
from google.colab import files

def show_grid(images, titles=None, cols=3, figsize=(14,8), cmap=None):
    rows = (len(images) + cols - 1)//cols
    fig, axs = plt.subplots(rows, cols, figsize=figsize)
    axs = axs.flatten()
    for ax in axs[len(images):]:
        ax.axis('off')
    for i, im in enumerate(images):
        ax = axs[i]
        if im is None:
            ax.axis('off'); continue
        if im.ndim == 2:
            ax.imshow(im, cmap=cmap)
        else:
            ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
        if titles and i < len(titles):
            ax.set_title(titles[i], fontsize=12)
        ax.axis('off')
    plt.tight_layout(); plt.show()

# Upload image
print("Upload one image file now (jpg/png).")
uploaded = files.upload()
if not uploaded:
    raise FileNotFoundError("No files uploaded.")
fname = list(uploaded.keys())[0]
img = cv2.imdecode(np.frombuffer(uploaded[fname], np.uint8), cv2.IMREAD_COLOR)
if img is None:
    raise ValueError("Couldn't decode uploaded image.")
h,w = img.shape[:2]
print(f"Loaded {fname} -> shape {img.shape}")

# ----- OpenCV-based transforms -----
def translate_cv(img, tx, ty):
    M = np.float32([[1,0,tx],[0,1,ty]])
    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))

def rotate_cv(img, angle_deg):
    center = (img.shape[1]//2, img.shape[0]//2)
    M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)
    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))

def resize_cv(img, scale):
    return cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)

def flip_cv(img, mode):
    return cv2.flip(img, mode)  # 1 horizontal, 0 vertical

translated = translate_cv(img, 30, 50)
rot45 = rotate_cv(img, 45)
small = resize_cv(img, 0.5)
large = resize_cv(img, 1.5)
flip_h = flip_cv(img, 1)
flip_v = flip_cv(img, 0)

show_grid([img, translated, rot45, small, large, flip_h, flip_v],
          titles=["Original","Translated (30,50)","Rotated 45°","Resized 0.5x","Resized 1.5x","Flip H","Flip V"],
          cols=4, figsize=(16,8))

# ----- NumPy-only affine (inverse mapping, nearest-neighbor) -----
def apply_affine_numpy(img, M, out_shape):
    # M: 2x3 mapping src->dest like cv2.warpAffine.
    A = np.vstack([M, [0,0,1]])
    A_inv = np.linalg.inv(A)
    h_out, w_out = out_shape
    out = np.zeros((h_out, w_out, img.shape[2]), dtype=img.dtype)
    ys, xs = np.indices((h_out, w_out))
    ones = np.ones_like(xs)
    dest_h = np.stack([xs.ravel(), ys.ravel(), ones.ravel()], axis=0)
    src_h = A_inv.dot(dest_h)
    src_x = np.rint(src_h[0,:]).astype(int)
    src_y = np.rint(src_h[1,:]).astype(int)
    valid = (src_x >= 0) & (src_x < img.shape[1]) & (src_y >= 0) & (src_y < img.shape[0])
    out[ys.ravel()[valid], xs.ravel()[valid]] = img[src_y[valid], src_x[valid]]
    return out

# translation matrix
M_trans = np.array([[1,0,30],[0,1,50]], dtype=float)

# rotation about center via T2*R*T1
angle = 45
theta = radians(angle)
R = np.array([[cos(theta), -sin(theta), 0],[sin(theta), cos(theta), 0]])
cx, cy = w/2.0, h/2.0
T1 = np.array([[1,0,-cx],[0,1,-cy]])
T2 = np.array([[1,0,cx],[0,1,cy]])
M_rot_center = (np.vstack([T2, [0,0,1]]) @ np.vstack([R, [0,0,1]]) @ np.vstack([T1, [0,0,1]]))[:2,:]

trans_np = apply_affine_numpy(img, M_trans, (h,w))
rot_np = apply_affine_numpy(img, M_rot_center, (h,w))
res_small_np = apply_affine_numpy(img, np.array([[0.5,0,0],[0,0.5,0]]), (int(h*0.5), int(w*0.5)))
res_large_np = apply_affine_numpy(img, np.array([[1.5,0,0],[0,1.5,0]]), (int(h*1.5), int(w*1.5)))

show_grid([img, trans_np, rot_np, res_small_np, res_large_np],
          titles=["Original","Translated (numpy)","Rotated (numpy)","Resized 0.5x (numpy)","Resized 1.5x (numpy)"],
          cols=3, figsize=(14,9))

# Save outputs
out_dir = "/content/lab2_outputs"
os.makedirs(out_dir, exist_ok=True)
cv2.imwrite(os.path.join(out_dir, "translated_cv.jpg"), translated)
cv2.imwrite(os.path.join(out_dir, "rotated45_cv.jpg"), rot45)
cv2.imwrite(os.path.join(out_dir, "translated_np.jpg"), trans_np)
print("Saved Lab-2 examples to:", out_dir)

# Lab-3: Image Filters, Smoothing, and Noise tests


!pip install --quiet opencv-python-headless matplotlib

import os, cv2, numpy as np
import matplotlib.pyplot as plt
from google.colab import files

def show_grid(images, titles=None, cols=3, figsize=(14,8), cmap=None):
    rows = (len(images) + cols - 1)//cols
    fig, axs = plt.subplots(rows, cols, figsize=figsize)
    axs = axs.flatten()
    for ax in axs[len(images):]:
        ax.axis('off')
    for i, im in enumerate(images):
        ax = axs[i]
        if im is None:
            ax.axis('off'); continue
        if im.ndim == 2:
            ax.imshow(im, cmap=cmap)
        else:
            ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
        if titles and i < len(titles):
            ax.set_title(titles[i], fontsize=12)
        ax.axis('off')
    plt.tight_layout(); plt.show()

# Upload image
print("Upload one image file now (jpg/png).")
uploaded = files.upload()
if not uploaded:
    raise FileNotFoundError("No files uploaded.")
fname = list(uploaded.keys())[0]
img = cv2.imdecode(np.frombuffer(uploaded[fname], np.uint8), cv2.IMREAD_COLOR)
if img is None:
    raise ValueError("Couldn't decode uploaded image.")
print(f"Loaded {fname} -> shape {img.shape}")

# Convert to gray for many filters (keep color for bilateral)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# ----- Gaussian blur with sigma = 0,1,2,3 -----
def gaussian_blur(img, sigma):
    if sigma == 0:
        return img.copy()
    k = max(3, int(6*sigma+1))
    if k % 2 == 0: k += 1
    return cv2.GaussianBlur(img, (k,k), sigmaX=sigma)

gauss_list = [gaussian_blur(gray, s) for s in [0,1,2,3]]
show_grid(gauss_list, titles=["sigma=0","sigma=1","sigma=2","sigma=3"], cols=4, figsize=(12,4), cmap='gray')

# ----- Median filters 3x3 and 5x5 -----
med3 = cv2.medianBlur(gray, 3)
med5 = cv2.medianBlur(gray, 5)
show_grid([gray, med3, med5], titles=["Original Gray","Median 3x3","Median 5x5"], cols=3, figsize=(12,4), cmap='gray')

# ----- Bilateral filter (color) -----
bilat_a = cv2.bilateralFilter(img, d=5, sigmaColor=50, sigmaSpace=50)
bilat_b = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)
show_grid([img, bilat_a, bilat_b], titles=["Original Color","Bilateral (5,50,50)","Bilateral (9,75,75)"], cols=3, figsize=(12,4))

# ----- Add noise: Gaussian and Salt & Pepper -----
def add_gaussian_noise(img, mean=0, var=10):
    imgf = img.astype(np.float32)
    sigma = var**0.5
    noise = np.random.normal(mean, sigma, img.shape)
    out = imgf + noise
    return np.clip(out, 0, 255).astype(np.uint8)

def add_salt_pepper(img, amount=0.02):
    out = img.copy()
    h,w = out.shape[:2]
    num = int(amount * h * w)
    # salt
    coords = [np.random.randint(0, i-1, num) for i in (h,w)]
    out[coords[0], coords[1]] = 255
    # pepper
    coords = [np.random.randint(0, i-1, num) for i in (h,w)]
    out[coords[0], coords[1]] = 0
    return out

g_noisy = add_gaussian_noise(gray, mean=0, var=25)
sp_noisy = add_salt_pepper(gray, amount=0.03)
show_grid([gray, g_noisy, sp_noisy], titles=["Original Gray","Gaussian noise (var=25)","Salt&Pepper 3%"], cols=3, figsize=(12,4), cmap='gray')

# ----- Apply filters to noisy images and show results -----
g_on_g = gaussian_blur(g_noisy, 1.5)
m_on_sp3 = cv2.medianBlur(sp_noisy, 3)
m_on_sp5 = cv2.medianBlur(sp_noisy, 5)
show_grid([g_noisy, g_on_g], titles=["Gaussian noisy","After Gaussian blur (σ=1.5)"], cols=2, figsize=(10,4), cmap='gray')
show_grid([sp_noisy, m_on_sp3, m_on_sp5], titles=["Salt&Pepper noisy","Median 3x3","Median 5x5"], cols=3, figsize=(12,4), cmap='gray')

# ----- Simple table (print) of observations -----
observations = [
    ("Gaussian (small σ)", "Gaussian noise", "Removes Gaussian noise well; blurs edges moderately"),
    ("Median (3x3/5x5)", "Salt & Pepper", "Excellent for impulse noise; 5x5 stronger but blurs small details"),
    ("Bilateral", "Edge-preserving smoothing", "Preserves edges while smoothing; slower than Gaussian"),
    ("Over-smoothing", "Any", "Loss of fine details (bad for text or QR codes)")
]
print("Filter summary (Filter | Best for | Notes):")
for r in observations:
    print("-", r[0], "|", r[1], "|", r[2])

# Save outputs
out_dir = "/content/lab3_outputs"
os.makedirs(out_dir, exist_ok=True)
cv2.imwrite(os.path.join(out_dir, "gaussian_sigma2_gray.jpg"), gauss_list[2])
cv2.imwrite(os.path.join(out_dir, "median5_gray.jpg"), med5)
cv2.imwrite(os.path.join(out_dir, "bilateral_b.jpg"), bilat_b)
cv2.imwrite(os.path.join(out_dir, "gauss_noisy.jpg"), g_noisy)
cv2.imwrite(os.path.join(out_dir, "sp_noisy.jpg"), sp_noisy)
print("Saved Lab-3 examples to:", out_dir)



#lab-1
# color_space_analysis.py
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from collections import Counter

# ----- CONFIG -----
IMG_PATH = "/content/wp3.jpg"   # path to the cat image you gave
OUT_DIR = "/mnt/data/color_analysis_outputs"
os.makedirs(OUT_DIR, exist_ok=True)

# ----- HELPERS -----
def print_image_info(path, img):
    # file info
    filesize = os.path.getsize(path)
    h, w = img.shape[:2]
    channels = 1 if img.ndim == 2 else img.shape[2]
    dtype = img.dtype
    bit_depth = img.dtype.itemsize * 8  # bits per channel
    print(f"File: {path}")
    print(f" - Width x Height: {w} x {h}")
    print(f" - Channels (array): {channels}")
    print(f" - Dtype: {dtype} -> {bit_depth} bits per channel")
    print(f" - File size: {filesize/1024:.2f} KB")

def show_grid(images, titles, figsize=(12,8), cmap='gray', save_as=None):
    n = len(images)
    cols = min(3, n)
    rows = (n + cols - 1) // cols
    plt.figure(figsize=figsize)
    for i, (im, t) in enumerate(zip(images, titles), 1):
        plt.subplot(rows, cols, i)
        # if image has 3 channels and dtype isn't float normalized, convert BGR->RGB for display
        if im is None:
            plt.title(t)
            plt.axis('off')
            continue
        if im.ndim == 3:
            # assume BGR (OpenCV) — convert to RGB for matplotlib display
            plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
            plt.axis('off')
        else:
            plt.imshow(im, cmap=cmap)
            plt.axis('off')
        plt.title(t)
    plt.tight_layout()
    if save_as:
        plt.savefig(save_as, bbox_inches='tight')
        print(f"Saved visualization -> {save_as}")
    plt.show()

def normalize_for_display(channel):
    """ Normalize single-channel image to 0-255 uint8 for display """
    ch = channel.astype(np.float32)
    ch_min, ch_max = ch.min(), ch.max()
    if ch_max - ch_min < 1e-6:
        return np.zeros_like(ch, dtype=np.uint8)
    norm = 255 * (ch - ch_min) / (ch_max - ch_min)
    return norm.astype(np.uint8)

def color_highlight_channel(bgr, channel_index):
    """
    Return an image that highlights one channel in its color while zeroing others.
    channel_index: 0=B,1=G,2=R
    """
    zeros = np.zeros_like(bgr[:,:,0])
    ch = bgr[:,:,channel_index]
    if channel_index == 2:   # R highlighted: produce (0,0,R) then convert to BGR format - but OpenCV uses BGR so merge order is B,G,R
        merged = cv2.merge([zeros, zeros, ch])
    elif channel_index == 1:
        merged = cv2.merge([zeros, ch, zeros])
    else:
        merged = cv2.merge([ch, zeros, zeros])
    return merged

# ----- MAIN PROCESS -----
# 1) Load image (preserve channels)
img_bgr = cv2.imread(IMG_PATH, cv2.IMREAD_UNCHANGED)
if img_bgr is None:
    raise FileNotFoundError(f"Could not read image at {IMG_PATH}")

print_image_info(IMG_PATH, img_bgr)

# If image has alpha channel, drop it (common for PNG). We'll note if alpha existed.
if img_bgr.ndim == 3 and img_bgr.shape[2] == 4:
    print(" - Note: Image has alpha channel; dropping alpha for color-space conversions.")
    img_bgr = img_bgr[:, :, :3]

# 2) Basic RGB (OpenCV returns BGR)
b, g, r = cv2.split(img_bgr)

# 3) Convert to HSV
img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
h, s, v = cv2.split(img_hsv)
# OpenCV Hue range: [0,179], Saturation and Value: [0,255]

# 4) Convert to YCbCr (OpenCV uses YCrCb ordering)
# OpenCV color conversion constant: COLOR_BGR2YCrCb returns channels in order [Y, Cr, Cb]
img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)
Y = img_ycrcb[:, :, 0]
Cr = img_ycrcb[:, :, 1]
Cb = img_ycrcb[:, :, 2]
# If you want the more commonly named order Y, Cb, Cr, we can swap:
# Y, Cb, Cr = img_ycrcb[..., 0], img_ycrcb[..., 2], img_ycrcb[..., 1]

# 5) Visualize channels
# Prepare grayscale visualizations (normalized)
r_gray = normalize_for_display(r)
g_gray = normalize_for_display(g)
b_gray = normalize_for_display(b)

h_display = normalize_for_display(h)        # Hue normalized for visualization
s_display = normalize_for_display(s)
v_display = normalize_for_display(v)

Y_gray = normalize_for_display(Y)
Cb_gray = normalize_for_display(Cb)
Cr_gray = normalize_for_display(Cr)

# Color-highlighted R/G/B (so human sees the color contribution)
r_color = color_highlight_channel(img_bgr, 2)
g_color = color_highlight_channel(img_bgr, 1)
b_color = color_highlight_channel(img_bgr, 0)

# Show a grid: original, R_color, G_color, B_color, H, S, V, Y, Cb, Cr
images = [
    img_bgr,
    r_color, g_color, b_color,
    h_display, s_display, v_display,
    Y_gray, Cb_gray, Cr_gray
]
titles = [
    "Original (BGR)",
    "Red channel (highlighted)", "Green channel (highlighted)", "Blue channel (highlighted)",
    "Hue (normalized)", "Saturation", "Value (luminance proxy)",
    "Y (luma)", "Cb (blue diff)", "Cr (red diff)"
]
show_grid(images, titles, figsize=(14,10), save_as=os.path.join(OUT_DIR, "all_channels.png"))

# Save individual channel images (optional)
cv2.imwrite(os.path.join(OUT_DIR, "orig_rgb.png"), cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))
cv2.imwrite(os.path.join(OUT_DIR, "r_gray.png"), r_gray)
cv2.imwrite(os.path.join(OUT_DIR, "g_gray.png"), g_gray)
cv2.imwrite(os.path.join(OUT_DIR, "b_gray.png"), b_gray)
cv2.imwrite(os.path.join(OUT_DIR, "h.png"), h_display)
cv2.imwrite(os.path.join(OUT_DIR, "s.png"), s_display)
cv2.imwrite(os.path.join(OUT_DIR, "v.png"), v_display)
cv2.imwrite(os.path.join(OUT_DIR, "Y.png"), Y_gray)
cv2.imwrite(os.path.join(OUT_DIR, "Cb.png"), Cb_gray)
cv2.imwrite(os.path.join(OUT_DIR, "Cr.png"), Cr_gray)

print("Saved per-channel images to:", OUT_DIR)

# 6) Analysis: dominant hue + luminance stats
# Build a histogram of hue values
h_flat = h.flatten()
# Hue values in OpenCV range [0,179]. Count most frequent value (mode)
counts = Counter(h_flat.tolist())
most_common_hue, count = counts.most_common(1)[0]
total = len(h_flat)
percentage = 100.0 * count / total

# Convert hue to degrees: OpenCV H*2 => degrees in [0,360)
hue_degrees = most_common_hue * 2

print(f"\nDominant hue (mode): {most_common_hue} (OpenCV units) ≈ {hue_degrees:.1f}° ; frequency {count}/{total} = {percentage:.2f}%")
print("Saturation mean:", float(np.mean(s)))
print("Value (V) mean (luminance proxy):", float(np.mean(v)))
print("Y (luma) mean:", float(np.mean(Y)))
print("Y (luma) std dev:", float(np.std(Y)))

# 7) Quick interpretation (text output)
print("\nQuick interpretation:")
print(" - Hue (H) shows dominant color (here printed as a hue angle).")
print(" - S (saturation) indicates color purity (low = more gray).")
print(" - V (value) and Y channel indicate brightness/luminance.")
print(" - Cb/Cr are chroma components; useful when separating color from intensity (tracking, compression).")
print("\nSituations where each color model is useful:")
print(" - RGB/BGR: low-level pixel manipulation, direct display, simple tasks.")
print(" - HSV: color-based segmentation or tracking (select hue ranges regardless of lightness).")
print(" - YCbCr: video/compression and tasks that separate luminance from chrominance (useful for compression, skin detection with chroma thresholds).")

# 8) Optionally show a hue histogram plot
plt.figure(figsize=(8,3))
plt.hist(h_flat, bins=180, range=(0,180))
plt.title("Hue histogram (OpenCV 0-179)")
plt.xlabel("Hue (OpenCV units)")
plt.ylabel("Count")
plt.tight_layout()
hist_path = os.path.join(OUT_DIR, "hue_histogram.png")
plt.savefig(hist_path)
print("Saved hue histogram ->", hist_path)
plt.show()